{
    "name": "root",
    "gauges": {
        "EatOther.Policy.Entropy.mean": {
            "value": 1.4124869108200073,
            "min": 1.410561442375183,
            "max": 1.4195563793182373,
            "count": 10
        },
        "EatOther.Policy.Entropy.sum": {
            "value": 70737.34375,
            "min": 70423.4609375,
            "max": 72317.8828125,
            "count": 10
        },
        "EatOther.Environment.EpisodeLength.mean": {
            "value": 117.26117647058824,
            "min": 76.61270801815431,
            "max": 149.35329341317365,
            "count": 10
        },
        "EatOther.Environment.EpisodeLength.sum": {
            "value": 49836.0,
            "min": 47422.0,
            "max": 50641.0,
            "count": 10
        },
        "EatOther.Step.mean": {
            "value": 499990.0,
            "min": 49957.0,
            "max": 499990.0,
            "count": 10
        },
        "EatOther.Step.sum": {
            "value": 499990.0,
            "min": 49957.0,
            "max": 499990.0,
            "count": 10
        },
        "EatOther.Policy.ExtrinsicValueEstimate.mean": {
            "value": 190.91024780273438,
            "min": 21.322954177856445,
            "max": 360.9403076171875,
            "count": 10
        },
        "EatOther.Policy.ExtrinsicValueEstimate.sum": {
            "value": 188810.234375,
            "min": 20000.931640625,
            "max": 432045.5625,
            "count": 10
        },
        "EatOther.Environment.CumulativeReward.mean": {
            "value": 948.5929563208188,
            "min": 471.5447714685345,
            "max": 996.8153712024742,
            "count": 10
        },
        "EatOther.Environment.CumulativeReward.sum": {
            "value": 403152.00643634796,
            "min": 160796.76707077026,
            "max": 553878.8621392846,
            "count": 10
        },
        "EatOther.Policy.ExtrinsicReward.mean": {
            "value": 948.5929563208188,
            "min": 471.5447714685345,
            "max": 996.8153712024742,
            "count": 10
        },
        "EatOther.Policy.ExtrinsicReward.sum": {
            "value": 403152.00643634796,
            "min": 160796.76707077026,
            "max": 553878.8621392846,
            "count": 10
        },
        "EatOther.Losses.PolicyLoss.mean": {
            "value": 0.024398880437947808,
            "min": 0.02189903001456211,
            "max": 0.027232586415484546,
            "count": 10
        },
        "EatOther.Losses.PolicyLoss.sum": {
            "value": 0.12199440218973903,
            "min": 0.0888338749917845,
            "max": 0.13616293207742272,
            "count": 10
        },
        "EatOther.Losses.ValueLoss.mean": {
            "value": 267680.59567708336,
            "min": 99412.011015625,
            "max": 3715077.1895572916,
            "count": 10
        },
        "EatOther.Losses.ValueLoss.sum": {
            "value": 1338402.9783854168,
            "min": 460359.40390625,
            "max": 18575385.947786458,
            "count": 10
        },
        "EatOther.Policy.LearningRate.mean": {
            "value": 1.5625774791440007e-05,
            "min": 1.5625774791440007e-05,
            "max": 0.00028455990514670003,
            "count": 10
        },
        "EatOther.Policy.LearningRate.sum": {
            "value": 7.812887395720003e-05,
            "min": 7.812887395720003e-05,
            "max": 0.0012841704719432,
            "count": 10
        },
        "EatOther.Policy.Epsilon.mean": {
            "value": 0.10520856,
            "min": 0.10520856,
            "max": 0.1948533,
            "count": 10
        },
        "EatOther.Policy.Epsilon.sum": {
            "value": 0.5260428,
            "min": 0.5260428,
            "max": 0.9280568000000001,
            "count": 10
        },
        "EatOther.Policy.Beta.mean": {
            "value": 0.0002699071440000001,
            "min": 0.0002699071440000001,
            "max": 0.004743179670000001,
            "count": 10
        },
        "EatOther.Policy.Beta.sum": {
            "value": 0.0013495357200000004,
            "min": 0.0013495357200000004,
            "max": 0.021410034320000004,
            "count": 10
        },
        "EatOther.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "EatOther.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1640555683",
        "python_version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\unityProjects\\AI_cell_battle\\venv\\Scripts\\mlagents-learn --force",
        "mlagents_version": "0.27.0",
        "mlagents_envs_version": "0.27.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.5",
        "end_time_seconds": "1640556077"
    },
    "total": 394.469161,
    "count": 1,
    "self": 0.008022499999981392,
    "children": {
        "run_training.setup": {
            "total": 0.030470599999999903,
            "count": 1,
            "self": 0.030470599999999903
        },
        "TrainerController.start_learning": {
            "total": 394.4306679,
            "count": 1,
            "self": 0.45512279999815064,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.561356400000001,
                    "count": 1,
                    "self": 10.561356400000001
                },
                "TrainerController.advance": {
                    "total": 383.3542340000019,
                    "count": 18764,
                    "self": 0.409061300003259,
                    "children": {
                        "env_step": {
                            "total": 227.92896929999927,
                            "count": 18764,
                            "self": 183.98702710000234,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 43.670434399997106,
                                    "count": 18764,
                                    "self": 1.6090025999955913,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 42.061431800001515,
                                            "count": 15658,
                                            "self": 17.258120100002674,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 24.80331169999884,
                                                    "count": 15658,
                                                    "self": 24.80331169999884
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.2715077999998332,
                                    "count": 18764,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 384.592498299999,
                                            "count": 18764,
                                            "is_parallel": true,
                                            "self": 234.01920830000066,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0005463999999992808,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00017189999999978056,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00037449999999950023,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00037449999999950023
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 150.57274359999838,
                                                    "count": 18764,
                                                    "is_parallel": true,
                                                    "self": 4.2037831999908235,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 9.394169999999665,
                                                            "count": 18764,
                                                            "is_parallel": true,
                                                            "self": 9.394169999999665
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 129.38261320000578,
                                                            "count": 18764,
                                                            "is_parallel": true,
                                                            "self": 129.38261320000578
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 7.592177200002119,
                                                            "count": 18764,
                                                            "is_parallel": true,
                                                            "self": 2.6922832000010803,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 4.899894000001039,
                                                                    "count": 37528,
                                                                    "is_parallel": true,
                                                                    "self": 4.899894000001039
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 155.01620339999937,
                            "count": 18764,
                            "self": 0.7676506000003371,
                            "children": {
                                "process_trajectory": {
                                    "total": 52.208316199999004,
                                    "count": 18764,
                                    "self": 52.14034429999903,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.067971899999975,
                                            "count": 1,
                                            "self": 0.067971899999975
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 102.04023660000003,
                                    "count": 48,
                                    "self": 76.8361398000012,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 25.204096799998826,
                                            "count": 1440,
                                            "self": 25.204096799998826
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.999999749903509e-07,
                    "count": 1,
                    "self": 8.999999749903509e-07
                },
                "TrainerController._save_models": {
                    "total": 0.059953799999959756,
                    "count": 1,
                    "self": 0.020463500000005297,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.03949029999995446,
                            "count": 1,
                            "self": 0.03949029999995446
                        }
                    }
                }
            }
        }
    }
}